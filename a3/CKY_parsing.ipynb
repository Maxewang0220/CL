{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "from ast import parse\n",
    "\n",
    "# define the path\n",
    "GRAMMAR_PATH = \"./atis/atis-grammar-cnf.cfg\"\n",
    "SENTENCES_PATH = \"./atis/atis-test-sentences.txt\""
   ],
   "id": "3884e2a42b6d2019",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "\n",
    "grammar = nltk.data.load(GRAMMAR_PATH)  # load the grammar\n",
    "raw_sentences = nltk.data.load(SENTENCES_PATH)  # load raw sentences\n",
    "test_sentences = nltk.parse.util.extract_test_sentences(raw_sentences)  # extract test sentences\n",
    "\n",
    "print(grammar)\n",
    "print(raw_sentences)\n",
    "for s in test_sentences:\n",
    "    print(s)"
   ],
   "id": "616555ae7c30e175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## test the parser\n",
    "# initialize the parser\n",
    "parser = nltk.parse.BottomUpChartParser(grammar)\n",
    "\n",
    "#try to parse several test sentences\n",
    "for sentence in test_sentences[:10]:\n",
    "    try:\n",
    "        trees = list(parser.parse(sentence[0]))\n",
    "        if trees:\n",
    "            print(\"Sentence: \", sentence[0], len(trees))\n",
    "        else:\n",
    "            print(\"Parsing failed for sentence: \", sentence[0])\n",
    "    except Exception as e:\n",
    "        print(\"Exception: \", e)\n",
    "        print(\"Parsing failed for sentence: \", sentence[0])"
   ],
   "id": "e85aae483a1fc1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def CKY_reconize(sentence, grammar: nltk.grammar.CFG):\n",
    "    # initialize the chart\n",
    "    n = len(sentence)\n",
    "    chart = [[set() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # fill in the diagonal of the chart\n",
    "    for i in range(n):\n",
    "        # get the production whose rhs is the word i\n",
    "        for production in grammar.productions(rhs=sentence[i]):\n",
    "            # add the lhs of the production to the cell\n",
    "            chart[i][i].add(production.lhs())\n",
    "\n",
    "    # main body of the CKY algorithm\n",
    "    # traverse the chart for each width b\n",
    "    for b in range(2, n + 1):\n",
    "        # for each start position i\n",
    "        for i in range(0, n - b + 1):\n",
    "            # for each left width k\n",
    "            for k in range(0, b - 1):\n",
    "                # for each non-terminal B and C\n",
    "                # if there is a production B -> C in the grammar\n",
    "                # add [B, C] to the cell\n",
    "                for B in chart[i][i + k]:\n",
    "                    for C in chart[i + k + 1][i + b - 1]:\n",
    "                        # nltk grammar productions only accept one item in the rhs\n",
    "                        for production in grammar.productions(rhs=B):\n",
    "                            if production.rhs() == (B, C):\n",
    "                                chart[i][i + b - 1].add(production.lhs())\n",
    "\n",
    "    # if the start symbol is in chart[0][n-1], the sentence can be parsed\n",
    "    if grammar.start() in chart[0][n - 1]:\n",
    "        return True\n",
    "\n",
    "    return False"
   ],
   "id": "42d0e095f6bde98d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extra: Optimized running efficiency\n",
    "def CKY_reconize_optimized(sentence, grammar: nltk.grammar.CFG):\n",
    "    # initialize the chart\n",
    "    n = len(sentence)\n",
    "    chart = [[set() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # Use production cache: map RHS -> LHS\n",
    "    # Binary rules (e.g., A -> B C)\n",
    "    binary_rules = dict()\n",
    "\n",
    "    # add all binary rules to the cache\n",
    "    for production in grammar.productions():\n",
    "        if len(production.rhs()) == 2:\n",
    "            if production.rhs() not in binary_rules:\n",
    "                binary_rules[production.rhs()] = []\n",
    "                binary_rules[production.rhs()].append(production.lhs())\n",
    "            else:\n",
    "                binary_rules[production.rhs()].append(production.lhs())\n",
    "\n",
    "    # fill in the diagonal of the chart\n",
    "    for i in range(n):\n",
    "        # get the production whose rhs is the word i\n",
    "        for production in grammar.productions(rhs=sentence[i]):\n",
    "            # add the lhs of the production to the cell\n",
    "            chart[i][i].add(production.lhs())\n",
    "\n",
    "    # main body of the CKY algorithm\n",
    "    # traverse the chart for each width b\n",
    "    for b in range(2, n + 1):\n",
    "        # for each start position i\n",
    "        for i in range(0, n - b + 1):\n",
    "            # for each left width k\n",
    "            for k in range(0, b - 1):\n",
    "                # for each non-terminal B and C\n",
    "                # if there is a production B -> C in the grammar\n",
    "                # add [B, C] to the cell\n",
    "                for B in chart[i][i + k]:\n",
    "                    for C in chart[i + k + 1][i + b - 1]:\n",
    "                        # look up the cache for the lhs\n",
    "                        for lhs in binary_rules.get((B, C), []):\n",
    "                            chart[i][i + b - 1].add(lhs)\n",
    "\n",
    "    # if the start symbol is in chart[0][n-1], the sentence can be parsed\n",
    "    if grammar.start() in chart[0][n - 1]:\n",
    "        return True\n",
    "\n",
    "    return False"
   ],
   "id": "a8f619def9ffd243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(test_sentences)):\n",
    "    print(i, test_sentences[i][0], end='\\t')\n",
    "    print(CKY_reconize(test_sentences[i][0], grammar))"
   ],
   "id": "ba0b9528462d7f25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(test_sentences)):\n",
    "    print(i, test_sentences[i][0], end='\\t')\n",
    "    print(CKY_reconize_optimized(test_sentences[i][0], grammar))"
   ],
   "id": "4b1dc5204a3dc653",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CKY parser\n",
    "def CKY_parse(sentence, grammar: nltk.grammar.CFG):\n",
    "    n = len(sentence)\n",
    "    chart = [[set() for _ in range(n)] for _ in range(n)]\n",
    "    # use dicts as back pointers\n",
    "    back_pointers = [[{} for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    binary_rules = dict()\n",
    "\n",
    "    for production in grammar.productions():\n",
    "        if len(production.rhs()) == 2:\n",
    "            if production.rhs() not in binary_rules:\n",
    "                binary_rules[production.rhs()] = []\n",
    "                binary_rules[production.rhs()].append(production.lhs())\n",
    "            else:\n",
    "                binary_rules[production.rhs()].append(production.lhs())\n",
    "\n",
    "    for i in range(n):\n",
    "        for production in grammar.productions(rhs=sentence[i]):\n",
    "            chart[i][i].add(production.lhs())\n",
    "            back_pointers[i][i][production.lhs()] = [sentence[i]]\n",
    "\n",
    "    # main body of the CKY algorithm\n",
    "    for b in range(2, n + 1):\n",
    "        for i in range(0, n - b + 1):\n",
    "            for k in range(0, b - 1):\n",
    "                for B in chart[i][i + k]:\n",
    "                    for C in chart[i + k + 1][i + b - 1]:\n",
    "                        for lhs in binary_rules.get((B, C), []):\n",
    "                            chart[i][i + b - 1].add(lhs)\n",
    "\n",
    "                            # add back pointers\n",
    "                            if lhs not in back_pointers[i][i + b - 1]:\n",
    "                                back_pointers[i][i + b - 1][lhs] = []\n",
    "                            back_pointers[i][i + b - 1][lhs].append((B, C, i + k))\n",
    "\n",
    "    # return back pointers\n",
    "    if grammar.start() in chart[0][n - 1]:\n",
    "        return True, back_pointers\n",
    "\n",
    "    return False, None"
   ],
   "id": "70fa33d7b4142257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.tree import ImmutableTree\n",
    "\n",
    "\n",
    "# extract the trees from the back pointers\n",
    "def extract_trees(back_pointers, i, j, start_symbol):\n",
    "    if i == j:\n",
    "        return {ImmutableTree(start_symbol, [back_pointers[i][j][start_symbol][0]])}\n",
    "\n",
    "    trees = set()\n",
    "\n",
    "    for B, C, k in back_pointers[i][j][start_symbol]:\n",
    "        left_trees = extract_trees(back_pointers, i, k, B)\n",
    "        right_trees = extract_trees(back_pointers, k + 1, j, C)\n",
    "\n",
    "        # combine the left and right subtrees\n",
    "        for left in left_trees:\n",
    "            for right in right_trees:\n",
    "                trees.add(ImmutableTree(start_symbol, [left, right]))\n",
    "\n",
    "    return trees"
   ],
   "id": "c07cb54a348f932e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test the CKY parser\n",
    "for sentence in test_sentences[:2]:\n",
    "    success, back_pointers = CKY_parse(sentence[0], grammar)\n",
    "    if success:\n",
    "        trees = extract_trees(back_pointers, 0, len(sentence[0]) - 1, grammar.start())\n",
    "        print(\"Sentence: \", sentence[0], len(trees))\n",
    "        for tree in trees:\n",
    "            tree = nltk.tree.Tree.fromstring(str(tree))\n",
    "            tree.pretty_print()\n",
    "            tree.draw()\n",
    "    else:\n",
    "        print(\"Parsing failed for sentence: \", sentence[0])"
   ],
   "id": "5ebccc104c6587b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Output the parsing results and compare with standard results\n",
    "for sentence in test_sentences:\n",
    "    success, back_pointers = CKY_parse(sentence[0], grammar)\n",
    "    try:\n",
    "        tree_num = len(list(parser.parse(sentence[0])))\n",
    "    except Exception as e:\n",
    "        tree_num = 0\n",
    "\n",
    "    trees = []\n",
    "    if success:\n",
    "        trees = extract_trees(back_pointers, 0, len(sentence[0]) - 1, grammar.start())\n",
    "        print(sentence[0], '\\t', len(trees))\n",
    "    else:\n",
    "        print(sentence[0], '\\t', 0)\n",
    "\n",
    "    if len(trees) != tree_num:\n",
    "        print(\"Error: \", sentence[0], len(trees), tree_num)\n",
    "        exit()\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "id": "1f65d293db678d46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extra: Figure out how to compute the number of parse trees with backpointers\n",
    "def count_trees(back_pointers, i, j, start_symbol):\n",
    "    if i == j:\n",
    "        return 1\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for B, C, k in back_pointers[i][j][start_symbol]:\n",
    "        left_count = count_trees(back_pointers, i, k, B)\n",
    "        right_count = count_trees(back_pointers, k + 1, j, C)\n",
    "\n",
    "        # just multiply the left trees number and right trees number\n",
    "        count += left_count * right_count\n",
    "\n",
    "    return count"
   ],
   "id": "ac60459210a82f8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extra: test count_trees\n",
    "for sentence in test_sentences:\n",
    "    success, back_pointers = CKY_parse(sentence[0], grammar)\n",
    "    try:\n",
    "        tree_num = len(list(parser.parse(sentence[0])))\n",
    "    except Exception as e:\n",
    "        tree_num = 0\n",
    "\n",
    "    tree_count = 0\n",
    "    if success:\n",
    "        tree_count = count_trees(back_pointers, 0, len(sentence[0]) - 1, grammar.start())\n",
    "\n",
    "    if tree_count != tree_num:\n",
    "        print(\"Error: \", sentence[0], tree_count, tree_num)\n",
    "        exit()\n",
    "\n",
    "    print(sentence[0], '\\t', tree_count)\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "id": "3fb92ab8669f4869",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extra: compare the efficiency improvement\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    success, back_pointers = CKY_parse(sentence[0], grammar)\n",
    "    if success:\n",
    "        trees = extract_trees(back_pointers, 0, len(sentence[0]) - 1, grammar.start())\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    success, back_pointers = CKY_parse(sentence[0], grammar)\n",
    "    if success:\n",
    "        tree_num = count_trees(back_pointers, 0, len(sentence[0]) - 1, grammar.start())\n",
    "\n",
    "t3 = time.time()\n",
    "\n",
    "print(\"Time cost improvement: \", ((t2 - t1) - (t3 - t2)) / (t2 - t1))"
   ],
   "id": "dae1e854aea17ee2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
