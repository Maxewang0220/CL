{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.probability import (FreqDist, ConditionalFreqDist, ConditionalProbDist, MLEProbDist, SimpleGoodTuringProbDist)\n",
    "from nltk.util import ngrams"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "685d43fdbf9b50ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ml_estimator(freqdist):\n",
    "    return MLEProbDist(freqdist)\n",
    "\n",
    "def goodturing_estimator(freqdist):\n",
    "    return SimpleGoodTuringProbDist(freqdist)\n",
    "\n",
    "def read_file(file_path):\n",
    "    words = []\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_tokens = line.lower().split(\" \")\n",
    "            words += line_tokens\n",
    "    return words\n",
    "\n",
    "# # use the generate method from the NLTK class ProbDistI to generate the next random word\n",
    "def generate_text(ngram, n, length=100):\n",
    "    # # add the padding start symbol to the init context\n",
    "    context = tuple([ngram._start_symbol] * (n - 1))\n",
    "    result = list(context)\n",
    "    for i in range(length):\n",
    "        if context in ngram._counter:\n",
    "            prob_dist = ngram[context]\n",
    "            # # predict the next word\n",
    "            word = prob_dist.generate()\n",
    "        else:\n",
    "            word = ngram._end_symbol\n",
    "        \n",
    "        result.append(word)\n",
    "        \n",
    "        if word == ngram._end_symbol:\n",
    "            break\n",
    "        # # update the context    \n",
    "        context = tuple(result[-(n-1):])\n",
    "        \n",
    "    return ' '.join(result)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "73c61270bc49e1cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BasicNgram(ConditionalProbDist):\n",
    "    \"\"\"\n",
    "    Define and train an Ngram Model over the corpus represented by the list words. \n",
    "    Given an BasicNgram instance ngram and a (n-1)-gram context (i.e., a tuple of n-1 strings), \n",
    "    a call to ngram[context] returns a nltk.probability.ProbDistI object representing the Probability distribution P(.|context) over possible values for the next word. \n",
    "    Be aware that context has to be a tuple, even if context is a unigram (see example below)\n",
    "    \n",
    "    >>> corpus=['a','b','b','a']\n",
    "    >>> bigram=BasicNgram(2,corpus)\n",
    "    >>> bigram.contexts()\n",
    "    [('<$>',), ('a',), ('b',)]\n",
    "    >>> p_b=bigram[('b',)] #not bigram['b']!!!\n",
    "    >>> p_b.prob('a')\n",
    "    0.5\n",
    "    >>> p_b.prob('b')\n",
    "    0.5\n",
    "    \n",
    "    :param n: the dimension of the n-grams (i.e. the size of the context+1).\n",
    "    :type n: int\n",
    "    :param corpus: \n",
    "    :type corpus: list(Str)\n",
    "    \n",
    "    other parameters are optional and may be omitted. They define whether to add artificial symbols before or after the word list, \n",
    "    and whether to use another estimation methods than maximum likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, words, start_symbol=\"<$>\", end_symbol=\"</$>\", pad_left=True, pad_right=False,\n",
    "                 estimator=ml_estimator):\n",
    "        assert (n > 0)\n",
    "        self._n = n\n",
    "        self._words = words\n",
    "        self._counter = ConditionalFreqDist()\n",
    "        self._start_symbol = start_symbol\n",
    "        self._end_symbol = end_symbol\n",
    "        self._pad_left = pad_left\n",
    "        self._pad_right = pad_right\n",
    "        self._train()\n",
    "        super().__init__(self._counter, estimator)\n",
    "\n",
    "    def _train(self):\n",
    "        _ngrams = self.generate_ngrams()\n",
    "        for ngram in _ngrams:\n",
    "            context = ngram[0:-1]\n",
    "            outcome = ngram[-1]\n",
    "            self._counter[context][outcome] += 1\n",
    "\n",
    "    \"\"\"\n",
    "    returns an iterable over the ngrams of the word corpus\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_ngrams(self):\n",
    "        return ngrams(self._words, self._n, pad_left=self._pad_left, pad_right=self._pad_right,\n",
    "                      left_pad_symbol=self._start_symbol,\n",
    "                      right_pad_symbol=self._end_symbol)\n",
    "\n",
    "    \"\"\"                                                                                                                                                                                                                                                                                                                                                               \n",
    "    Return the list of contexts                                                                                                                                                                                                                                                                                                                                       \n",
    "    \"\"\"\n",
    "\n",
    "    def contexts(self):\n",
    "        return list(self.conditions())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "25ae1769e1b96d0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = './kingjamesbible_tokenized.txt'\n",
    "\n",
    "corpus = read_file(file_path)\n",
    "\n",
    "print(corpus[:15])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "83134bca62398573"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 2-gram\n",
    "bigram = BasicNgram(2, corpus)\n",
    "\n",
    "bigram.contexts()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "71f404dfc8d6225e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_text(bigram, 2, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fc7d65b2609956da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 3-gram\n",
    "trigram = BasicNgram(3, corpus)\n",
    "\n",
    "trigram.contexts()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f05d39b91b1586fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_text(trigram, 3 ,100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95c531ad97d00d18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 4-gram\n",
    "four_gram = BasicNgram(4, corpus)\n",
    "\n",
    "four_gram.contexts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad7bdbe31b800e66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_text(four_gram, 4, 100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c524ba16b58807f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
