{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685d43fdbf9b50ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.146841Z",
     "start_time": "2024-11-03T22:57:39.714717Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.probability import (FreqDist, ConditionalFreqDist, ConditionalProbDist, MLEProbDist, SimpleGoodTuringProbDist)\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c61270bc49e1cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.154871Z",
     "start_time": "2024-11-03T22:57:40.150352Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def ml_estimator(freqdist):\n",
    "    return MLEProbDist(freqdist)\n",
    "\n",
    "\n",
    "def goodturing_estimator(freqdist):\n",
    "    return SimpleGoodTuringProbDist(freqdist)\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    words = []\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_tokens = line.lower().split(\" \")\n",
    "            words += line_tokens\n",
    "    return words\n",
    "\n",
    "\n",
    "# # use the generate method from the NLTK class ProbDistI to generate the next random word\n",
    "def generate_text(ngram, n, length=100):\n",
    "    # # add the padding start symbol to the init context\n",
    "    context = tuple([ngram._start_symbol] * (n - 1))\n",
    "    result = list(context)\n",
    "    for i in range(length):\n",
    "        if context in ngram._counter:\n",
    "            prob_dist = ngram[context]\n",
    "            # # predict the next word\n",
    "            word = prob_dist.generate()\n",
    "        else:\n",
    "            word = ngram._end_symbol\n",
    "\n",
    "        result.append(word)\n",
    "\n",
    "        if word == ngram._end_symbol:\n",
    "            break\n",
    "        # # update the context    \n",
    "        context = tuple(result[-(n - 1):])\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ae1769e1b96d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.282326Z",
     "start_time": "2024-11-03T22:57:40.277547Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BasicNgram(ConditionalProbDist):\n",
    "    \"\"\"\n",
    "    Define and train an Ngram Model over the corpus represented by the list words. \n",
    "    Given an BasicNgram instance ngram and a (n-1)-gram context (i.e., a tuple of n-1 strings), \n",
    "    a call to ngram[context] returns a nltk.probability.ProbDistI object representing the Probability distribution P(.|context) over possible values for the next word. \n",
    "    Be aware that context has to be a tuple, even if context is a unigram (see example below)\n",
    "    \n",
    "    >>> corpus=['a','b','b','a']\n",
    "    >>> bigram=BasicNgram(2,corpus)\n",
    "    >>> bigram.contexts()\n",
    "    [('<$>',), ('a',), ('b',)]\n",
    "    >>> p_b=bigram[('b',)] #not bigram['b']!!!\n",
    "    >>> p_b.prob('a')\n",
    "    0.5\n",
    "    >>> p_b.prob('b')\n",
    "    0.5\n",
    "    \n",
    "    :param n: the dimension of the n-grams (i.e. the size of the context+1).\n",
    "    :type n: int\n",
    "    :param corpus: \n",
    "    :type corpus: list(Str)\n",
    "    \n",
    "    other parameters are optional and may be omitted. They define whether to add artificial symbols before or after the word list, \n",
    "    and whether to use another estimation methods than maximum likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, words, start_symbol=\"<$>\", end_symbol=\"</$>\", pad_left=True, pad_right=False,\n",
    "                 estimator=ml_estimator):\n",
    "        assert (n > 0)\n",
    "        self._n = n\n",
    "        self._words = words\n",
    "        self._counter = ConditionalFreqDist()\n",
    "        self._start_symbol = start_symbol\n",
    "        self._end_symbol = end_symbol\n",
    "        self._pad_left = pad_left\n",
    "        self._pad_right = pad_right\n",
    "        self._train()\n",
    "        super().__init__(self._counter, estimator)\n",
    "\n",
    "    def _train(self):\n",
    "        _ngrams = self.generate_ngrams()\n",
    "        for ngram in _ngrams:\n",
    "            context = ngram[0:-1]\n",
    "            outcome = ngram[-1]\n",
    "            self._counter[context][outcome] += 1\n",
    "\n",
    "    \"\"\"\n",
    "    returns an iterable over the ngrams of the word corpus\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_ngrams(self):\n",
    "        return ngrams(self._words, self._n, pad_left=self._pad_left, pad_right=self._pad_right,\n",
    "                      left_pad_symbol=self._start_symbol,\n",
    "                      right_pad_symbol=self._end_symbol)\n",
    "\n",
    "    \"\"\"                                                                                                                                                                                                                                                                                                                                                               \n",
    "    Return the list of contexts                                                                                                                                                                                                                                                                                                                                       \n",
    "    \"\"\"\n",
    "\n",
    "    def contexts(self):\n",
    "        return list(self.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83134bca62398573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.343155Z",
     "start_time": "2024-11-03T22:57:40.293763Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.\\n', 'and', 'the', 'earth', 'was']\n"
     ]
    }
   ],
   "source": [
    "file_path = './kingjamesbible_tokenized.txt'\n",
    "\n",
    "corpus = read_file(file_path)\n",
    "\n",
    "# # avoid corpus is null\n",
    "print(corpus[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f404dfc8d6225e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.830154Z",
     "start_time": "2024-11-03T22:57:40.348987Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<$>',),\n",
       " ('in',),\n",
       " ('the',),\n",
       " ('beginning',),\n",
       " ('god',),\n",
       " ('created',),\n",
       " ('heaven',),\n",
       " ('and',),\n",
       " ('earth',),\n",
       " ('.\\n',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 2-gram\n",
    "bigram = BasicNgram(2, corpus)\n",
    "\n",
    "bigram.contexts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7d65b2609956da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:40.844042Z",
     "start_time": "2024-11-03T22:57:40.837554Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<$> in an high priest upon one man .\\n and so many prophets four , cease .\\n and the ground : yet learned wisdom of babylon shall be told you .\\n the heaven ; and thy wife and with him to the daughter of arimathaea , by esaias prophesy again .\\n for for they shall lift up axes and the disciples were both .\\n for john saw jesus : then judgment seat , who can not one that the grass faileth for stubble .\\n now and took every good cheer up to another of the son is a servant ; as'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(bigram, 2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac6dd336facfed",
   "metadata": {},
   "source": [
    "# 2-gram\n",
    "\n",
    "## **1.Coherence**:\n",
    "**The 2-gram model produces output which is quite disjointed and lacks grammatical coherence. The system selects each word based on only one preceding word, which often leads to nonsensical or fragmented sentences.**\n",
    "\n",
    "## **2.Creativity**:\n",
    "**The text feels fragmented, with phrases and partial ideas rather than complete sentences. There are abrupt topic shifts, like going from \"high priest\" to \"prophets\" and then to \"judgment seat.\"**\n",
    "\n",
    "## **3.Quality**:\n",
    "**Very low quality with unreadable text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05d39b91b1586fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:41.778986Z",
     "start_time": "2024-11-03T22:57:40.857741Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<$>', '<$>'),\n",
       " ('<$>', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'beginning'),\n",
       " ('beginning', 'god'),\n",
       " ('god', 'created'),\n",
       " ('created', 'the'),\n",
       " ('the', 'heaven'),\n",
       " ('heaven', 'and'),\n",
       " ('and', 'the')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 3-gram\n",
    "trigram = BasicNgram(3, corpus)\n",
    "\n",
    "trigram.contexts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1f51a6c769c2c",
   "metadata": {},
   "source": [
    "# 3-gram\n",
    "## **1.Coherence**:\n",
    "**The 3-gram model shows some improvement in coherence. Here are more syntactically valid sequences and recognizable phrases.**\n",
    "\n",
    "## **2.Creativity**:\n",
    "**The output feels less random than the 2-gram model, but still displays some unexpected transitions.**\n",
    "\n",
    "## **3.Quality**:\n",
    "**While some phrases make sense individually, the text as a whole lacks logical flow. This model is closer to producing human-readable sentences, although the generated text still feels strange.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c531ad97d00d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:41.788763Z",
     "start_time": "2024-11-03T22:57:41.785793Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<$> <$> in the midst of thee .\\n a man , named gamaliel , and his return from me .\\n and he overlaid the bars thereof .\\n and when joab heard the voice of the gershonites , in the city shall they be visited .\\n then said jesus unto the going down to gihon .\\n and moses said unto them ;\\n thou shalt save thy people israel didst thou set the sea ; and in judgment .\\n neither shall it be marvellous in mine own body , ye rejoice with all that their power is given unto it , and on him'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(trigram, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7bdbe31b800e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:43.315296Z",
     "start_time": "2024-11-03T22:57:41.800508Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<$>', '<$>', '<$>'),\n",
       " ('<$>', '<$>', 'in'),\n",
       " ('<$>', 'in', 'the'),\n",
       " ('in', 'the', 'beginning'),\n",
       " ('the', 'beginning', 'god'),\n",
       " ('beginning', 'god', 'created'),\n",
       " ('god', 'created', 'the'),\n",
       " ('created', 'the', 'heaven'),\n",
       " ('the', 'heaven', 'and'),\n",
       " ('heaven', 'and', 'the')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 4-gram\n",
    "four_gram = BasicNgram(4, corpus)\n",
    "\n",
    "four_gram.contexts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c524ba16b58807f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T22:57:43.325858Z",
     "start_time": "2024-11-03T22:57:43.322352Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<$> <$> <$> in the beginning of barley harvest .\\n and naomi said unto her , weep not : behold , i will break the staff of the bread of the increase of thy kine , and tied them to the border of arnon , but came not within the days appointed , and the sinite ,\\n and the sockets thereof , and joined the foundations .\\n be it known unto you , i have not proved them . and the king sent jehucal the son of jabesh in samaria , and unto all riches of the glory of the lord , and'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(four_gram, 4, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781634ae9e1acbfa",
   "metadata": {},
   "source": [
    "# 4-gram\n",
    "## **1.Coherence**:\n",
    "**The 4-gram model produces text that closely resembles human language in terms of sentence structure. Sequences like \"and naomi said unto her, weep not\" and \"i will break the staff of the bread of the increase of thy kine\" are almost plausible biblical phrases, albeit somewhat verbose.**\n",
    "\n",
    "## **2.Creativity**:\n",
    "**This model sacrifices some randomness, resulting in more readable text.**\n",
    "\n",
    "## **3.Quality**:\n",
    "**The quality of the generated text is the highest among these three n-gram model, with sentences that are more grammatically and semantically plausible.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
