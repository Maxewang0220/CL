{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from nltk.probability import (FreqDist, ConditionalFreqDist, ConditionalProbDist, MLEProbDist, SimpleGoodTuringProbDist)\n",
    "from nltk.util import ngrams"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:57.776095312Z",
     "start_time": "2024-08-28T08:45:57.719250453Z"
    }
   },
   "id": "685d43fdbf9b50ac"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def ml_estimator(freqdist):\n",
    "    return MLEProbDist(freqdist)\n",
    "\n",
    "def goodturing_estimator(freqdist):\n",
    "    return SimpleGoodTuringProbDist(freqdist)\n",
    "\n",
    "def read_file(file_path):\n",
    "    words = []\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_tokens = line.lower().split(\" \")\n",
    "            words += line_tokens\n",
    "    return words\n",
    "\n",
    "# # use the generate method from the NLTK class ProbDistI to generate the next random word\n",
    "def generate_text(ngram, n, length=100):\n",
    "    # # add the padding start symbol to the init context\n",
    "    context = tuple([ngram._start_symbol] * (n - 1))\n",
    "    result = list(context)\n",
    "    for i in range(length):\n",
    "        if context in ngram._counter:\n",
    "            prob_dist = ngram[context]\n",
    "            # # predict the next word\n",
    "            word = prob_dist.generate()\n",
    "        else:\n",
    "            word = ngram._end_symbol\n",
    "        \n",
    "        result.append(word)\n",
    "        \n",
    "        if word == ngram._end_symbol:\n",
    "            break\n",
    "        # # update the context    \n",
    "        context = tuple(result[-(n-1):])\n",
    "        \n",
    "    return ' '.join(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:57.776330228Z",
     "start_time": "2024-08-28T08:45:57.763884539Z"
    }
   },
   "id": "73c61270bc49e1cb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class BasicNgram(ConditionalProbDist):\n",
    "    \"\"\"\n",
    "    Define and train an Ngram Model over the corpus represented by the list words. \n",
    "    Given an BasicNgram instance ngram and a (n-1)-gram context (i.e., a tuple of n-1 strings), \n",
    "    a call to ngram[context] returns a nltk.probability.ProbDistI object representing the Probability distribution P(.|context) over possible values for the next word. \n",
    "    Be aware that context has to be a tuple, even if context is a unigram (see example below)\n",
    "    \n",
    "    >>> corpus=['a','b','b','a']\n",
    "    >>> bigram=BasicNgram(2,corpus)\n",
    "    >>> bigram.contexts()\n",
    "    [('<$>',), ('a',), ('b',)]\n",
    "    >>> p_b=bigram[('b',)] #not bigram['b']!!!\n",
    "    >>> p_b.prob('a')\n",
    "    0.5\n",
    "    >>> p_b.prob('b')\n",
    "    0.5\n",
    "    \n",
    "    :param n: the dimension of the n-grams (i.e. the size of the context+1).\n",
    "    :type n: int\n",
    "    :param corpus: \n",
    "    :type corpus: list(Str)\n",
    "    \n",
    "    other parameters are optional and may be omitted. They define whether to add artificial symbols before or after the word list, \n",
    "    and whether to use another estimation methods than maximum likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, words, start_symbol=\"<$>\", end_symbol=\"</$>\", pad_left=True, pad_right=False,\n",
    "                 estimator=ml_estimator):\n",
    "        assert (n > 0)\n",
    "        self._n = n\n",
    "        self._words = words\n",
    "        self._counter = ConditionalFreqDist()\n",
    "        self._start_symbol = start_symbol\n",
    "        self._end_symbol = end_symbol\n",
    "        self._pad_left = pad_left\n",
    "        self._pad_right = pad_right\n",
    "        self._train()\n",
    "        super().__init__(self._counter, estimator)\n",
    "\n",
    "    def _train(self):\n",
    "        _ngrams = self.generate_ngrams()\n",
    "        for ngram in _ngrams:\n",
    "            context = ngram[0:-1]\n",
    "            outcome = ngram[-1]\n",
    "            self._counter[context][outcome] += 1\n",
    "\n",
    "    \"\"\"\n",
    "    returns an iterable over the ngrams of the word corpus\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_ngrams(self):\n",
    "        return ngrams(self._words, self._n, pad_left=self._pad_left, pad_right=self._pad_right,\n",
    "                      left_pad_symbol=self._start_symbol,\n",
    "                      right_pad_symbol=self._end_symbol)\n",
    "\n",
    "    \"\"\"                                                                                                                                                                                                                                                                                                                                                               \n",
    "    Return the list of contexts                                                                                                                                                                                                                                                                                                                                       \n",
    "    \"\"\"\n",
    "\n",
    "    def contexts(self):\n",
    "        return list(self.conditions())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:57.776461379Z",
     "start_time": "2024-08-28T08:45:57.764104479Z"
    }
   },
   "id": "25ae1769e1b96d0c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.\\n', 'and', 'the', 'earth', 'was']\n"
     ]
    }
   ],
   "source": [
    "file_path = './kingjamesbible_tokenized.txt'\n",
    "\n",
    "corpus = read_file(file_path)\n",
    "\n",
    "print(corpus[:15])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:57.798730632Z",
     "start_time": "2024-08-28T08:45:57.764266537Z"
    }
   },
   "id": "83134bca62398573"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[('<$>',),\n ('in',),\n ('the',),\n ('beginning',),\n ('god',),\n ('created',),\n ('heaven',),\n ('and',),\n ('earth',),\n ('.\\n',)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 2-gram\n",
    "bigram = BasicNgram(2, corpus)\n",
    "\n",
    "bigram.contexts()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:58.557099925Z",
     "start_time": "2024-08-28T08:45:57.819899938Z"
    }
   },
   "id": "71f404dfc8d6225e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'<$> in the fishes , dwelling shall eat sufficiently , saying , and your god , shall run to the inner gate of the valley also will not my cause : behold , the men , proud have walked mournfully before me : for my father ; as this thing wherein are the people , how pleasant jewels , and if any deceit ;\\n save the reubenites , and unto the multitude throng him , and to day is , by his sister : it shall cause of gad , after they dwelt in pieces of abel and david dancing :'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(bigram, 2, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:58.557550807Z",
     "start_time": "2024-08-28T08:45:58.546486415Z"
    }
   },
   "id": "fc7d65b2609956da"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[('<$>', '<$>'),\n ('<$>', 'in'),\n ('in', 'the'),\n ('the', 'beginning'),\n ('beginning', 'god'),\n ('god', 'created'),\n ('created', 'the'),\n ('the', 'heaven'),\n ('heaven', 'and'),\n ('and', 'the')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 3-gram\n",
    "trigram = BasicNgram(3, corpus)\n",
    "\n",
    "trigram.contexts()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:59.794630166Z",
     "start_time": "2024-08-28T08:45:58.550892110Z"
    }
   },
   "id": "f05d39b91b1586fa"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'<$> <$> in the two tails of these abominations have the same is kelita , azariah the son of ebed , his statutes , nor hearkened to the king of assyria : thy walls are thrown down , and will cause them to eat and drink .\\n and it shall be heard among the children of israel .\\n therefore thus saith the lord said unto them , hearken unto the lord ; and roboam begat abia ; and he shall answer and say unto the two hundred and forty and five years shall ephraim be broken : but to the saints of'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(trigram, 3 ,100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:45:59.795002586Z",
     "start_time": "2024-08-28T08:45:59.784561785Z"
    }
   },
   "id": "95c531ad97d00d18"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('<$>', '<$>', '<$>'),\n ('<$>', '<$>', 'in'),\n ('<$>', 'in', 'the'),\n ('in', 'the', 'beginning'),\n ('the', 'beginning', 'god'),\n ('beginning', 'god', 'created'),\n ('god', 'created', 'the'),\n ('created', 'the', 'heaven'),\n ('the', 'heaven', 'and'),\n ('heaven', 'and', 'the')]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 4-gram\n",
    "four_gram = BasicNgram(4, corpus)\n",
    "\n",
    "four_gram.contexts()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:46:01.805625043Z",
     "start_time": "2024-08-28T08:45:59.788185909Z"
    }
   },
   "id": "ad7bdbe31b800e66"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'<$> <$> <$> in the beginning of the world , which have not known , and our lord jesus christ be with thy servants . and he arose out of his mother : and his commandments , and obey his voice to be heard .\\n for in him dwelleth all the fulness of the blessing wherewith his father blessed him : and he gave him a piece of money , then he shall make an atonement for you before the heathen , and will sup with him , he was there in the way , and hide thyself from them : thou shalt'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(four_gram, 4, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T08:46:01.806053106Z",
     "start_time": "2024-08-28T08:46:01.801841849Z"
    }
   },
   "id": "1c524ba16b58807f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
